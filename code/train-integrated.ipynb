{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fb155e9-b373-4b84-9ba4-ae1555b7a076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nnutil \n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "import math\n",
    "device = nnutil.device\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47b658d1-1c2c-4919-828c-939aa48c1556",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('TCGA-BRCA-Integrated-Data-Sampler.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "620a4416-75e2-4eec-bca8-c1b7d065b3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape:(2110, 2048), data_tensor:torch.Size([2110, 2048])\n"
     ]
    }
   ],
   "source": [
    "# 加载数据\n",
    "dataloader, data_tensor, normalized_tensor,data_y,ae_mean, ae_std = nnutil.data_prehandle(\n",
    "    file='TCGA-BRCA-Integrated-Data.csv', \n",
    "    df = df,\n",
    "    start=0,\n",
    "    label='label'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf7c7d52-be2a-4f0b-b9f6-92dd40590727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    422\n",
       "0    422\n",
       "2    422\n",
       "3    422\n",
       "1    422\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e37ddf6b-4f1f-400e-a463-fd7afb1df909",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnutil.setup_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a19cc6d1-42cd-4770-b7ed-d0bb760fc46d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9438, -1.1304, -1.1308,  ..., -1.1335, -0.1454,  1.0683],\n",
       "        [-1.1374, -1.1179, -1.0755,  ..., -1.1367, -0.8094, -1.1134],\n",
       "        [-0.2025, -1.1326, -1.1346,  ..., -1.1288,  0.9545,  1.0807],\n",
       "        ...,\n",
       "        [-1.0826, -1.1372, -1.1366,  ..., -1.1373, -0.0879,  0.3378],\n",
       "        [-0.7217, -1.1369, -1.1331,  ..., -1.1311, -0.1615,  0.0237],\n",
       "        [-0.9587, -1.1363, -1.1344,  ..., -1.1319, -0.0351,  0.9200]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45224dde-d356-445e-870c-391ce60e4ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1688, 2048])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将数据分为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalized_tensor, data_y, test_size=0.2, random_state=42)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67dd3ef4-9d2d-4458-a9be-9ec752fe34f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_445425/1342047294.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
      "/tmp/ipykernel_445425/1342047294.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.1374, -1.1180, -1.1229,  ..., -1.1174,  0.0290,  1.0825],\n",
       "         [ 0.1905, -1.1362, -1.1188,  ..., -1.1374, -1.1274,  0.4164],\n",
       "         [ 1.0611, -1.1371, -1.1371,  ..., -1.0889, -0.0795,  0.1145],\n",
       "         ...,\n",
       "         [-0.9189, -1.1363, -1.1343,  ..., -1.1229, -0.5819,  1.0731],\n",
       "         [-0.2807, -1.1320, -1.1223,  ..., -1.0424,  0.6984,  1.0564],\n",
       "         [-0.7677, -1.0779, -0.9763,  ..., -0.0561,  0.9293,  1.0791]]),\n",
       " tensor([1, 2, 4,  ..., 1, 1, 0]),\n",
       " tensor([[-0.4620, -0.4157, -1.1293,  ..., -1.1340,  1.0860,  1.0863],\n",
       "         [-0.9752, -1.1328, -1.1251,  ..., -1.1208,  0.8190,  1.0437],\n",
       "         [-0.4788, -1.1367, -1.1369,  ..., -1.1369,  0.9599,  0.9342],\n",
       "         ...,\n",
       "         [-1.1060, -1.1291, -1.1270,  ..., -1.1291,  0.2477,  0.8012],\n",
       "         [ 0.9956, -1.1246, -1.1303,  ..., -1.1372,  0.8230,  1.0863],\n",
       "         [-0.9925, -1.1218, -1.1362,  ..., -1.1304,  0.6845,  1.0343]]),\n",
       " tensor([2, 4, 2, 2, 0, 2, 4, 2, 3, 0, 3, 4, 3, 3, 4, 0, 4, 3, 1, 0, 3, 0, 4, 1,\n",
       "         2, 0, 1, 4, 3, 2, 4, 0, 1, 2, 0, 4, 3, 2, 2, 2, 2, 3, 3, 2, 2, 3, 3, 2,\n",
       "         2, 3, 1, 2, 1, 0, 2, 3, 3, 3, 0, 3, 2, 4, 0, 2, 3, 2, 2, 4, 2, 2, 1, 2,\n",
       "         3, 2, 0, 3, 4, 0, 3, 3, 2, 1, 4, 4, 1, 1, 2, 0, 0, 2, 2, 4, 2, 2, 2, 2,\n",
       "         2, 2, 2, 3, 3, 1, 4, 3, 0, 1, 2, 4, 4, 3, 1, 3, 1, 3, 3, 3, 1, 4, 1, 3,\n",
       "         4, 4, 1, 0, 3, 4, 1, 1, 3, 3, 4, 4, 2, 3, 1, 4, 2, 4, 2, 3, 0, 1, 0, 2,\n",
       "         1, 3, 1, 4, 2, 1, 2, 2, 2, 4, 2, 0, 0, 0, 2, 0, 3, 0, 1, 2, 3, 2, 1, 3,\n",
       "         0, 2, 2, 1, 3, 4, 1, 1, 1, 1, 1, 3, 2, 4, 2, 0, 3, 1, 0, 4, 3, 3, 2, 4,\n",
       "         3, 3, 4, 0, 3, 3, 4, 3, 4, 3, 4, 4, 2, 4, 0, 0, 0, 4, 0, 1, 2, 3, 4, 2,\n",
       "         0, 3, 3, 2, 4, 0, 3, 0, 3, 1, 2, 4, 0, 1, 2, 4, 2, 0, 3, 1, 1, 1, 1, 2,\n",
       "         1, 1, 0, 1, 2, 2, 2, 3, 2, 2, 0, 3, 2, 2, 3, 0, 3, 3, 1, 2, 4, 4, 0, 1,\n",
       "         1, 4, 4, 2, 3, 4, 1, 4, 3, 1, 4, 1, 3, 4, 3, 3, 0, 0, 1, 4, 3, 0, 1, 1,\n",
       "         0, 3, 1, 0, 2, 3, 0, 0, 4, 4, 1, 1, 2, 0, 4, 2, 0, 3, 0, 0, 1, 4, 2, 3,\n",
       "         3, 3, 0, 1, 1, 4, 0, 2, 2, 3, 4, 2, 2, 4, 3, 3, 4, 2, 2, 0, 4, 4, 1, 0,\n",
       "         1, 0, 0, 2, 1, 4, 1, 1, 4, 3, 3, 3, 0, 1, 0, 4, 1, 2, 0, 1, 1, 2, 2, 1,\n",
       "         1, 3, 1, 3, 4, 4, 3, 1, 2, 4, 0, 1, 2, 3, 1, 0, 3, 2, 1, 3, 1, 0, 0, 0,\n",
       "         4, 0, 3, 4, 2, 2, 4, 0, 4, 1, 0, 0, 0, 4, 0, 4, 2, 2, 0, 0, 3, 0, 2, 4,\n",
       "         3, 4, 0, 2, 0, 0, 4, 2, 4, 3, 0, 4, 2, 3]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 转化为 PyTorch 张量\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.to_numpy(), dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.to_numpy(), dtype=torch.long)\n",
    "X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2eaddc85-a132-492f-bd5d-c91ec4eff0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v: 0 ,num: 343\n",
      "v: 1 ,num: 346\n",
      "v: 2 ,num: 325\n",
      "v: 3 ,num: 331\n",
      "v: 4 ,num: 343\n"
     ]
    }
   ],
   "source": [
    "nnutil.count_num(y_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "442ac276-47a2-4eba-87b9-4ea52ab497a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v: 0 ,num: 79\n",
      "v: 1 ,num: 76\n",
      "v: 2 ,num: 97\n",
      "v: 3 ,num: 91\n",
      "v: 4 ,num: 79\n"
     ]
    }
   ],
   "source": [
    "nnutil.count_num(y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75b1cb6b-1d3b-4be6-85e3-c86a39ccb1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes, dim_feedforward=2048, nhead=8, nlayers=6, dropout=0.1):\n",
    "        super(TransformerClassifier, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.src_mask = None\n",
    "        self.encoder_num = 1024\n",
    "        self.fc = nn.Linear(self.input_dim, self.encoder_num)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=self.encoder_num,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=nlayers)\n",
    "        self.classifier = nn.Linear(self.encoder_num, num_classes)\n",
    "\n",
    "    def forward(self, src):\n",
    "        if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
    "            mask = self._generate_square_subsequent_mask(len(src)).to(src.device)\n",
    "            self.src_mask = mask\n",
    "        src = self.fc(src)\n",
    "        src = src * math.sqrt(self.encoder_num)\n",
    "        output = self.transformer_encoder(src, self.src_mask)\n",
    "        output = self.classifier(output)\n",
    "        return torch.squeeze(output)\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15fd17de-3e3c-439d-ae4d-500c92aed813",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = nnutil.CustomDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = nnutil.CustomDataset(X_test_tensor, y_test_tensor)\n",
    "batch_size = 128\n",
    "input_dim = X_train_tensor.shape[1]\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size)\n",
    "trans = TransformerClassifier(input_dim=input_dim, num_classes=5).to(device)\n",
    "para_file_dir = 'model/gen-met'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45b04883-6961-4f96-8cfb-f41083587516",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_losses = []\n",
    "epoch_test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22feb5c9-2c89-4c52-8a8e-ae0ff625bb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "\n",
    "def train_transformer(num_epochs=500, para_file='best_model.pth', model = None, train_loader = None):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    num_epochs = num_epochs\n",
    "    min_loss = 10000\n",
    "    best_file = para_file\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        epoch_test_loss = 0\n",
    "        num = 0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            num += 1\n",
    "            data = data.unsqueeze(1).to(device)  \n",
    "            target = target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            epoch_loss += loss.item()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "        epoch_loss = epoch_loss / num\n",
    "        epoch_losses.append(epoch_loss)\n",
    "        if (epoch_loss < min_loss):\n",
    "            min_loss = epoch_loss\n",
    "            print(f'save best model, epoch {epoch} loss = {min_loss}')\n",
    "            torch.save(model.state_dict(), best_file)\n",
    "        \n",
    "        \n",
    "        # print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_loss}')\n",
    "        ### Testing\n",
    "        model.eval()\n",
    "        num = 0\n",
    "        with torch.inference_mode():\n",
    "            for batch_idx, (data_test, target_test) in enumerate(train_loader):\n",
    "                num +=1\n",
    "                # 1. Forward pass\n",
    "                data_test = data_test.to(device)\n",
    "                target_test = target_test.to(device)\n",
    "                test_logits = model(data_test)\n",
    "                test_pred = torch.softmax(test_logits, dim=1).argmax(dim=1)\n",
    "                # 2. Calculate test loss and accuracy\n",
    "                test_loss = criterion(test_logits, target_test.to(device))\n",
    "                epoch_test_loss += test_loss.item()\n",
    "        epoch_test_loss = epoch_test_loss / num\n",
    "        epoch_test_losses.append(epoch_test_loss)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_loss}, Test Loss: {epoch_test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54d85d17-b650-4d15-a684-d663a4b4f2ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_transformer(num_epochs=5000, para_file=f'{para_file_dir}/best_model_gen-met_{input_dim}.pth', model = trans, train_loader = train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7769e7d-f3a7-4363-ae52-bc46ab14fba1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test set: 91.23222748815166%\n",
      "AUC: 0.9862324609538667\n",
      "Recall: 0.9218201347132575\n",
      "Precision: 0.9197604523361436\n",
      "F1 score: 0.9159938016973566\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(91.23222748815166,\n",
       " 0.9862324609538667,\n",
       " 0.9218201347132575,\n",
       " 0.9197604523361436,\n",
       " 0.9159938016973566)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnutil.test_transformer(para_file=f'{para_file_dir}/best_model_gen-met.pth', model = trans, test_loader = test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "428b2c97-7b51-4000-a21a-c83ee05a8908",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, recall_score, precision_score, f1_score, classification_report\n",
    "def test_transformer_subclass(para_file=\"best_model.pth\", model=None, test_loader=None):\n",
    "    model.load_state_dict(torch.load(para_file))\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    predicted_probs = []\n",
    "    targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.unsqueeze(1).to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(data)\n",
    "            predicted_probs.extend(\n",
    "                torch.softmax(output, dim=1).tolist()\n",
    "            )  \n",
    "            targets.extend(target.tolist())\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Overall Accuracy of the model on the test set: {accuracy}%\")\n",
    "\n",
    "    auc = roc_auc_score(targets, predicted_probs, multi_class=\"ovr\")\n",
    "    print(f\"Overall AUC: {auc}\")\n",
    "\n",
    "    predicted_labels = np.argmax(predicted_probs, axis=1)\n",
    "\n",
    "    # Generate classification report for each class\n",
    "    report = classification_report(targets, predicted_labels, output_dict=True)\n",
    "\n",
    "    num_classes = len(set(targets))\n",
    "    targets = np.array(targets)\n",
    "    label_size = [0 for i in range(num_classes)]\n",
    "    correct_label_size = [0 for i in range(num_classes)]\n",
    "    \n",
    "    for target, pred in zip(targets, predicted_labels):\n",
    "        label_size[target] += 1\n",
    "        if target == pred:\n",
    "            correct_label_size[target] += 1\n",
    "    print(f'{label_size=}')\n",
    "    print(f'{correct_label_size=}')\n",
    "    \n",
    "    for class_label in range(num_classes):\n",
    "        # Calculate per-class AUC\n",
    "        \n",
    "        class_probs = np.array(predicted_probs)[:, class_label]  # Probabilities for the current class\n",
    "        class_auc = roc_auc_score((targets == class_label).astype(int), class_probs)\n",
    "        class_label = str(class_label)\n",
    "        print(f\"*************************\")\n",
    "        print(f\"  Class {class_label}:\")\n",
    "        print(f\"  Precision: {report[class_label]['precision']:.4f}\")\n",
    "        print(f\"  Recall: {report[class_label]['recall']:.4f}\")\n",
    "        print(f\"  F1 Score: {report[class_label]['f1-score']:.4f}\")\n",
    "        print(f\"  AUC: {class_auc:.4f}\")\n",
    "        print(f\"*************************\")\n",
    "        print()\n",
    "    return accuracy, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1b076a0e-59da-435a-90b7-201614f80561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy of the model on the test set: 91.23222748815166%\n",
      "Overall AUC: 0.9862324609538667\n",
      "label_size=[79, 76, 97, 91, 79]\n",
      "correct_label_size=[77, 76, 69, 84, 79]\n",
      "*************************\n",
      "  Class 0:\n",
      "  Precision: 0.9747\n",
      "  Recall: 0.9747\n",
      "  F1 Score: 0.9747\n",
      "  AUC: 0.9993\n",
      "*************************\n",
      "\n",
      "*************************\n",
      "  Class 1:\n",
      "  Precision: 0.8837\n",
      "  Recall: 1.0000\n",
      "  F1 Score: 0.9383\n",
      "  AUC: 0.9994\n",
      "*************************\n",
      "\n",
      "*************************\n",
      "  Class 2:\n",
      "  Precision: 0.9452\n",
      "  Recall: 0.7113\n",
      "  F1 Score: 0.8118\n",
      "  AUC: 0.9565\n",
      "*************************\n",
      "\n",
      "*************************\n",
      "  Class 3:\n",
      "  Precision: 0.8077\n",
      "  Recall: 0.9231\n",
      "  F1 Score: 0.8615\n",
      "  AUC: 0.9764\n",
      "*************************\n",
      "\n",
      "*************************\n",
      "  Class 4:\n",
      "  Precision: 0.9875\n",
      "  Recall: 1.0000\n",
      "  F1 Score: 0.9937\n",
      "  AUC: 0.9996\n",
      "*************************\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(91.23222748815166, 0.9862324609538667)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_transformer_subclass(para_file=f'{para_file_dir}/best_model_gen-met.pth', model = trans, test_loader = test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589f6332-1876-4bbf-a7af-800182874914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_losses(epoch_losses):\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.plot(epoch_losses)\n",
    "    plt.title(\"Training Loss per Epoch\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffc429d-9f0d-4762-83e2-8f300f54ca00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "loss_result = {}\n",
    "shape = X_train_tensor.shape[1]\n",
    "loss_result[\"dimension\"] = shape\n",
    "loss_result[\"train_loss\"] = epoch_losses\n",
    "loss_result[\"test_loss\"] = epoch_test_losses\n",
    "name = f\"loss_dim_{shape}.json\"\n",
    "with open(name, \"w\") as f:\n",
    "    json.dump(loss_result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a0a994-596a-4a36-a8c8-697788e8acb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(epoch_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6647c880-59dc-4544-96ce-52715b036b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(epoch_test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7444da40-e796-429f-9328-3160506e8ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
